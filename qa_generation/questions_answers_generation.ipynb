{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "782c75f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import random\n",
    "\n",
    "from config import GEMINI_API_KEY, TAVILY_API_KEY\n",
    "\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from langchain_core.prompts.prompt import PromptTemplate\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a9c929d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"GOOGLE_API_KEY\" not in os.environ:\n",
    "    os.environ[\"GOOGLE_API_KEY\"] = GEMINI_API_KEY\n",
    "\n",
    "\n",
    "if \"TAVILY_API_KEY\" not in os.environ:\n",
    "    os.environ[\"TAVILY_API_KEY\"] = TAVILY_API_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8a56b723",
   "metadata": {},
   "outputs": [],
   "source": [
    "questions_jsonl = \"questions_v2.jsonl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c6ba777c",
   "metadata": {},
   "outputs": [],
   "source": [
    "questions_answers_jsonl = \"questions_answers_v2.jsonl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e472898",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-2.0-flash\",\n",
    "    temperature=0.5 # We want some randomness\n",
    ")\n",
    "\n",
    "json_output_parser = JsonOutputParser()\n",
    "\n",
    "chain = llm | json_output_parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f006c0c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "search = TavilySearchResults(max_results=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "63fbb65b",
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_generation_prompt_template = PromptTemplate(\n",
    "    input_variables=[\"QUESTION_STRING\", \"RETRIEVED_CONTEXT\"],\n",
    "    template=\"\"\"\n",
    "You are a university assistant for Singapore University of Technology and Design (SUTD) to answer questions from prospective students about SUTD. Using the question below and a retrieved context, generate a concise and informative answer appropriate for a prospective student to SUTD.\n",
    "\n",
    "In addition to the answer, output a confidence score from 0 to 1 (as a float) in JSON format. The score should reflect how well the context supports your answer.\n",
    "\n",
    "Respond in the following JSON format:\n",
    "{{\n",
    "  \"answer\": \"<your answer here>\",\n",
    "  \"confidence\": <float between 0 and 1>\n",
    "}}\n",
    "\n",
    "Here is an example:\n",
    "\n",
    "Question: \"What kind of exchange programmes does SUTD offer?\"\n",
    "\n",
    "Context:\n",
    "--- START OF CONTEXT ---\n",
    "SUTD offers a range of global exchange programmes including academic exchanges with partner universities in the US, Europe, and Asia. These programmes typically last one term and allow students to take courses overseas while earning credits towards their SUTD degree.\n",
    "--- END OF CONTEXT ---\n",
    "\n",
    "Response:\n",
    "{{\n",
    "  \"answer\": \"SUTD offers exchange programmes with partner universities in regions like the US, Europe, and Asia. These usually last for one term and allow you to earn credits while studying abroad.\",\n",
    "  \"confidence\": 0.95\n",
    "}}\n",
    "\n",
    "Now, answer the following:\n",
    "\n",
    "Question: \"{QUESTION_STRING}\"\n",
    "\n",
    "Context:\n",
    "--- START OF CONTEXT ---\n",
    "{RETRIEVED_CONTEXT}\n",
    "--- END OF CONTEXT ---\n",
    "\n",
    "Response:\n",
    "\"\"\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b482ce59",
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = []\n",
    "\n",
    "with open(questions_jsonl, 'r') as f:\n",
    "    for line in f:\n",
    "        try:\n",
    "            question_dict = json.loads(line)\n",
    "            questions.append(question_dict['question'])\n",
    "        except:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2ca6aab9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313\n"
     ]
    }
   ],
   "source": [
    "print(len(questions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e28ea93f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.0-flash\"\n",
      "  }\n",
      "  quota_value: 15\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "}\n",
      "].\n",
      "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.0-flash\"\n",
      "  }\n",
      "  quota_value: 15\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 56\n",
      "}\n",
      "].\n",
      "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.0-flash\"\n",
      "  }\n",
      "  quota_value: 15\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 52\n",
      "}\n",
      "].\n",
      "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.0-flash\"\n",
      "  }\n",
      "  quota_value: 15\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 12\n",
      "}\n",
      "].\n",
      "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.0-flash\"\n",
      "  }\n",
      "  quota_value: 15\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 9\n",
      "}\n",
      "].\n",
      "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.0-flash\"\n",
      "  }\n",
      "  quota_value: 15\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 5\n",
      "}\n",
      "].\n",
      "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.0-flash\"\n",
      "  }\n",
      "  quota_value: 15\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 58\n",
      "}\n",
      "].\n",
      "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.0-flash\"\n",
      "  }\n",
      "  quota_value: 15\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 48\n",
      "}\n",
      "].\n"
     ]
    }
   ],
   "source": [
    "from tenacity import retry, stop_after_attempt, wait_exponential, retry_if_exception_message\n",
    "\n",
    "lexicon_question_search_query_pairs = {}\n",
    "\n",
    "@retry(\n",
    "    stop=stop_after_attempt(25),\n",
    "    wait=wait_exponential(multiplier=1, min=1, max=60),\n",
    "    retry=retry_if_exception_message(match=\"429|ResourceExhausted\")\n",
    ")\n",
    "def invoke_chain(chain, prompt):\n",
    "    return chain.invoke(prompt)\n",
    "\n",
    "random.shuffle(questions)\n",
    "\n",
    "for question in questions:\n",
    "    try:\n",
    "        query_search_results = search.invoke(question)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    prompt = qa_generation_prompt_template.format(\n",
    "        QUESTION_STRING=question,\n",
    "        RETRIEVED_CONTEXT=query_search_results \n",
    "    )\n",
    "\n",
    "    results = invoke_chain(chain, prompt)\n",
    "    \n",
    "    answer = results[\"answer\"]\n",
    "    confidence_score = results[\"confidence\"]\n",
    "    \n",
    "    try:\n",
    "        if float(confidence_score) > 0.75:\n",
    "            with open(questions_answers_jsonl, \"a\") as f:\n",
    "                f.write(json.dumps({\n",
    "                    \"question\": question,\n",
    "                    \"prompt\": prompt,\n",
    "                    \"answer\": answer,\n",
    "                    \"context\": query_search_results,\n",
    "                    \"confidence\": confidence_score\n",
    "                }) + '\\n')\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c494a61d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "capstone",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
